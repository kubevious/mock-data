apiVersion: packages.operators.coreos.com/v1
kind: PackageManifest
metadata:
  creationTimestamp: "2022-10-03T18:25:13Z"
  labels:
    catalog: operatorhubio-catalog
    catalog-namespace: olm
    operatorframework.io/arch.amd64: supported
    operatorframework.io/os.linux: supported
    provider: Red Hat
    provider-url: ""
  name: metering-upstream
  namespace: default
spec: {}
status:
  catalogSource: operatorhubio-catalog
  catalogSourceDisplayName: Community Operators
  catalogSourceNamespace: olm
  catalogSourcePublisher: OperatorHub.io
  channels:
  - currentCSV: metering-operator-upstream.v4.2.0
    currentCSVDesc:
      annotations:
        alm-examples: |-
          [
            {
              "apiVersion": "metering.openshift.io/v1",
              "kind": "MeteringConfig",
              "metadata": {
                "name": "operator-metering"
              },
              "spec": {
                "storage": {
                  "hive": {
                    "s3": {
                      "bucket": "bucketname/path/",
                      "createBucket": true,
                      "region": "us-west-1",
                      "secretName": "my-aws-secret"
                    },
                    "type": "s3"
                  },
                  "type": "hive"
                }
              }
            },
            {
              "apiVersion": "metering.openshift.io/v1",
              "kind": "Report",
              "metadata": {
                "name": "unready-deployment-replicas-hourly"
              },
              "spec": {
                "query": "unready-deployment-replicas",
                "schedule": {
                  "period": "hourly"
                }
              }
            },
            {
              "apiVersion": "metering.openshift.io/v1",
              "kind": "ReportQuery",
              "metadata": {
                "name": "unready-deployment-replicas"
              },
              "spec": {
                "columns": [
                  {
                    "name": "period_start",
                    "type": "timestamp"
                  },
                  {
                    "name": "period_end",
                    "type": "timestamp"
                  },
                  {
                    "name": "namespace",
                    "type": "varchar"
                  },
                  {
                    "name": "deployment",
                    "type": "varchar"
                  },
                  {
                    "name": "total_replica_unready_seconds",
                    "type": "double"
                  },
                  {
                    "name": "avg_replica_unready_seconds",
                    "type": "double"
                  }
                ],
                "inputs": [
                  {
                    "name": "ReportingStart",
                    "type": "time"
                  },
                  {
                    "name": "ReportingEnd",
                    "type": "time"
                  },
                  {
                    "default": "unready-deployment-replicas",
                    "name": "UnreadyDeploymentReplicasDataSourceName",
                    "type": "ReportDataSource"
                  }
                ],
                "query": "SELECT\n    timestamp '{| default .Report.ReportingStart .Report.Inputs.ReportingStart | prestoTimestamp |}' AS period_start,\n    timestamp '{| default .Report.ReportingEnd .Report.Inputs.ReportingEnd | prestoTimestamp |}' AS period_end,\n    labels['namespace'] AS namespace,\n    labels['deployment'] AS deployment,\n    sum(amount * \"timeprecision\") AS total_replica_unready_seconds,\n    avg(amount * \"timeprecision\") AS avg_replica_unready_seconds\nFROM {| dataSourceTableName .Report.Inputs.UnreadyDeploymentReplicasDataSourceName |}\nWHERE \"timestamp\" >= timestamp '{| default .Report.ReportingStart .Report.Inputs.ReportingStart | prestoTimestamp |}'\nAND \"timestamp\" < timestamp '{| default .Report.ReportingEnd .Report.Inputs.ReportingEnd | prestoTimestamp |}'\nGROUP BY labels['namespace'], labels['deployment']\nORDER BY total_replica_unready_seconds DESC, avg_replica_unready_seconds DESC, namespace ASC, deployment ASC\n"
              }
            },
            {
              "apiVersion": "metering.openshift.io/v1",
              "kind": "ReportDataSource",
              "metadata": {
                "name": "unready-deployment-replicas"
              },
              "spec": {
                "prometheusMetricsImporter": {
                  "query": "sum(kube_deployment_status_replicas_unavailable) by (namespace, deployment)\n"
                }
              }
            },
            {
              "apiVersion": "metering.openshift.io/v1",
              "kind": "StorageLocation",
              "metadata": {
                "name": "s3-storage-example"
              },
              "spec": {
                "hive": {
                  "databaseName": "metering-s3",
                  "location": "s3a://bucketName/pathInBucket",
                  "unmanagedDatabase": true
                }
              }
            },
            {
              "apiVersion": "metering.openshift.io/v1",
              "kind": "PrestoTable",
              "metadata": {
                "name": "example-baremetal-cost"
              },
              "spec": {
                "catalog": "hive",
                "unmanaged": false,
                "columns": [
                  {
                    "name": "cost_per_gigabyte_hour",
                    "type": "double"
                  },
                  {
                    "name": "cost_per_cpu_hour",
                    "type": "double"
                  },
                  {
                    "name": "currency",
                    "type": "varchar"
                  }
                ],
                "createTableAs": true,
                "query": "SELECT * FROM (\n  VALUES (10.00, 50.00, 'USD')\n) AS t (cost_per_gigabyte_hour, cost_per_cpu_hour, currency)\n",
                "schema": "default",
                "tableName": "example_baremetal_cost"
              }
            },
            {
              "apiVersion": "metering.openshift.io/v1",
              "kind": "HiveTable",
              "metadata": {
                "name": "apache-log",
                "annotations": {
                  "reference": "based on the RegEx example from https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-RowFormats&SerDe"
                }
              },
              "spec": {
                "columns": [
                  {
                    "name": "host",
                    "type": "string"
                  },
                  {
                    "name": "identity",
                    "type": "string"
                  },
                  {
                    "name": "user",
                    "type": "string"
                  },
                  {
                    "name": "time",
                    "type": "string"
                  },
                  {
                    "name": "request",
                    "type": "string"
                  },
                  {
                    "name": "status",
                    "type": "string"
                  },
                  {
                    "name": "size",
                    "type": "string"
                  },
                  {
                    "name": "referer",
                    "type": "string"
                  },
                  {
                    "name": "agent",
                    "type": "string"
                  }
                ],
                "databaseName": "default",
                "external": true,
                "fileFormat": "TEXTFILE",
                "location": "s3a://my-bucket/apache_logs",
                "rowFormat": "SERDE 'org.apache.hadoop.hive.serde2.RegexSerDe'\nWITH SERDEPROPERTIES (\n  \"input.regex\" = \"([^ ]*) ([^ ]*) ([^ ]*) (-|\\\\[[^\\\\]]*\\\\]) ([^ \\\"]*|\\\"[^\\\"]*\\\") (-|[0-9]*) (-|[0-9]*)(?: ([^ \\\"]*|\\\"[^\\\"]*\\\") ([^ \\\"]*|\\\"[^\\\"]*\\\"))?\"\n)\n",
                "tableName": "apache_log"
              }
            }
          ]
        capabilities: Basic Install
        categories: OpenShift Optional, Monitoring
        certified: "false"
        containerImage: quay.io/coreos/metering-ansible-operator:latest
        createdAt: "2019-01-01 11:59:59"
        description: Chargeback and reporting tool to provide accountability for how
          resources are used across a cluster
        operatorhub.io/ui-metadata-max-k8s-version: "1.21"
        repository: https://github.com/operator-framework/operator-metering
        support: Red Hat, Inc.
      apiservicedefinitions: {}
      customresourcedefinitions:
        owned:
        - description: An instance of Metering with high-level configuration
          displayName: Metering Configuration
          kind: MeteringConfig
          name: meteringconfigs.metering.openshift.io
          version: v1
        - description: A scheduled or on-off Metering Report summarizes data based
            on the query specified.
          displayName: Metering Report
          kind: Report
          name: reports.metering.openshift.io
          version: v1
        - description: A SQL query used by Metering to generate reports.
          displayName: Metering Report Query
          kind: ReportQuery
          name: reportqueries.metering.openshift.io
          version: v1
        - description: Used under-the-hood. A resource representing a database table
            in Presto. Used by ReportQueries to determine what tables exist, and by
            the HTTP API to determine how to query a table.
          displayName: Metering Data Source
          kind: ReportDataSource
          name: reportdatasources.metering.openshift.io
          version: v1
        - description: Represents a configurable storage location for Metering to
            store metering and report data.
          displayName: Metering Storage Location
          kind: StorageLocation
          name: storagelocations.metering.openshift.io
          version: v1
        - description: Used under-the-hood. A resource describing a source of data
            for usage by Report Queries.
          displayName: Metering Presto Table
          kind: PrestoTable
          name: prestotables.metering.openshift.io
          version: v1
        - description: Used under-the-hood. A resource representing a database table
            in Hive.
          displayName: Metering Hive Table
          kind: HiveTable
          name: hivetables.metering.openshift.io
          version: v1
      description: |
        Important:  Operator Metering is no longer under active development.
        Operator Metering is a chargeback and reporting tool to provide accountability for how resources are used across a cluster. Cluster admins can schedule reports based on historical usage data by Pod, Namespace, and Cluster wide. Operator Metering is part of the [Operator Framework](https://coreos.com/blog/introducing-operator-framework-metering).

        Read the user guide for more details on [running and viewing your first report](https://github.com/operator-framework/operator-metering/blob/master/Documentation/using-metering.md).

        ### Core capabilities

        * **Chargeback/Showback** - Break down the reserved and utlized resources requested by applications.

        * **Pod, Namespace & Cluster Reports** - Built in reports exist to break down CPU and RAM in any way you desire.

        * **Scheduled Reports** - Schedule reports to run on a standard interval, eg. daily or monthly

        * **Post-Processing** - Reports are generated in CSV format and stored in persistent storage for further post-processing. Use this to send reminder emails, integrate into your ERP system, or graph on a dashboard.

        * **HTTP API** - Reports can be queried from an in-cluster HTTP API in addition to reading from persistent storage.

        ### Before you start

        Metering runs a big data stack to crunch your data and requires at least 4GB of RAM and 4 CPU cores. At least one Node should have 2GB of RAM and 2 CPU cores. Memory and CPU consumption may often be lower, but will spike when running reports, or collecting data for larger clusters.

        ### Common Configurations

        Metering works out of the box without any customizations or configuration. Read the [full documentation](https://github.com/operator-framework/operator-metering/blob/master/Documentation/metering-config.md) for more details.

        * **Use a specific StorageClass** - Follow the example to [use your own StorageClass](https://github.com/operator-framework/operator-metering/blob/master/manifests/metering-config/shared-storage.yaml) instead of the Dynamic Provisioner.

        * **Store data in S3 instead of PV** - Store your report output [in an S3 bucket](https://github.com/operator-framework/operator-metering/blob/master/Documentation/configuring-storage.md#storing-data-in-s3) instead of a PersistentVolume.

        * **Configure AWS Billing Data Source** - To assign Pod $$ costs on AWS, create a [read-only IAM user](https://github.com/operator-framework/operator-metering/blob/master/Documentation/configuring-aws-billing.md) ([example-policy](https://github.com/operator-framework/operator-metering/blob/master/Documentation/aws/read-only.json)) and [configure Metering](https://github.com/operator-framework/operator-metering/blob/master/manifests/metering-config/aws-billing.yaml) to use it.
      displayName: Metering
      installModes:
      - supported: true
        type: OwnNamespace
      - supported: true
        type: SingleNamespace
      - supported: false
        type: MultiNamespace
      - supported: false
        type: AllNamespaces
      keywords:
      - metering metrics reporting prometheus chargeback
      links:
      - name: Documentation
        url: https://github.com/operator-framework/operator-metering/blob/master/Documentation/index.md
      maintainers:
      - email: sd-operator-metering@redhat.com
        name: Red Hat
      maturity: stable
      minKubeVersion: 1.11.0
      provider:
        name: Red Hat
      relatedImages:
      - quay.io/coreos/metering-ansible-operator:release-4.2
      version: 4.2.0
    name: stable
  defaultChannel: stable
  packageName: metering-upstream
  provider:
    name: Red Hat
